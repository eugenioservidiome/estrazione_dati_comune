"""Generate run_report.md and audit CSV."""

from pathlib import Path
from typing import Dict, List
from datetime import datetime


def generate_run_report(output_path: Path, stats: Dict, comune: str, 
                       base_url: str, years: List[int]):
    """
    Generate comprehensive run_report.md.
    
    Expected stats keys:
    - crawl: {pdfs_found, html_found, time}
    - download: {total, downloaded, cached, deduplicated, failed, time, cache_hit_rate}
    - extract: {total, extracted, cached, failed, time, cache_hit_rate}
    - index: {total_docs, by_year, time}
    - fill: {total_cells, filled, not_found, coverage, time}
    - not_found_list: [indicators]
    """
    
    report_lines = [
        f"# Extraction Report: {comune}",
        f"",
        f"**Generated:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}",
        f"",
        f"## Configuration",
        f"- **Comune:** {comune}",
        f"- **Domain:** {base_url}",
        f"- **Years:** {', '.join(map(str, years))}",
        f"",
        f"## Crawling",
        f"- **PDFs found:** {stats.get('crawl', {}).get('pdfs_found', 0)}",
        f"- **HTML pages:** {stats.get('crawl', {}).get('html_found', 0)}",
        f"- **Time:** {stats.get('crawl', {}).get('time', 0):.2f}s",
        f"",
        f"## Download",
        f"- **Total PDFs:** {stats.get('download', {}).get('total', 0)}",
        f"- **Downloaded:** {stats.get('download', {}).get('downloaded', 0)}",
        f"- **Cached (reused):** {stats.get('download', {}).get('cached', 0)}",
        f"- **Deduplicated:** {stats.get('download', {}).get('deduplicated', 0)}",
        f"- **Failed:** {stats.get('download', {}).get('failed', 0)}",
        f"- **Cache hit rate:** {stats.get('download', {}).get('cache_hit_rate', 0):.1%}",
        f"- **Time:** {stats.get('download', {}).get('time', 0):.2f}s",
        f"",
        f"## Text Extraction",
        f"- **Total PDFs:** {stats.get('extract', {}).get('total', 0)}",
        f"- **Extracted:** {stats.get('extract', {}).get('extracted', 0)}",
        f"- **Cached (reused):** {stats.get('extract', {}).get('cached', 0)}",
        f"- **Failed:** {stats.get('extract', {}).get('failed', 0)}",
        f"- **Cache hit rate:** {stats.get('extract', {}).get('cache_hit_rate', 0):.1%}",
        f"- **Time:** {stats.get('extract', {}).get('time', 0):.2f}s",
        f"",
        f"## Indexing",
        f"- **Total documents indexed:** {stats.get('index', {}).get('total_docs', 0)}",
    ]
    
    # Add per-year breakdown
    by_year = stats.get('index', {}).get('by_year', {})
    if by_year:
        report_lines.append("")
        report_lines.append("### Documents by Year:")
        for year, count in sorted(by_year.items()):
            report_lines.append(f"- **{year}:** {count} documents")
    
    report_lines.extend([
        f"",
        f"- **Time:** {stats.get('index', {}).get('time', 0):.2f}s",
        f"",
        f"## Data Filling",
        f"- **Total cells:** {stats.get('fill', {}).get('total_cells', 0)}",
        f"- **Filled:** {stats.get('fill', {}).get('filled', 0)}",
        f"- **Not found:** {stats.get('fill', {}).get('not_found', 0)}",
        f"- **Coverage:** {stats.get('fill', {}).get('coverage', 0):.1%}",
        f"- **Time:** {stats.get('fill', {}).get('time', 0):.2f}s",
        f"",
    ])
    
    # Add NOT_FOUND list (limit to 50)
    not_found_list = stats.get('not_found_list', [])
    if not_found_list:
        report_lines.append("## Not Found Indicators (top 50):")
        report_lines.append("")
        for item in not_found_list[:50]:
            if isinstance(item, dict):
                indicator = item.get('indicator', '')
                year = item.get('year', '')
                report_lines.append(f"- {indicator} ({year})")
            else:
                report_lines.append(f"- {item}")
        report_lines.append("")
    
    # Total time
    total_time = sum([
        stats.get('crawl', {}).get('time', 0),
        stats.get('download', {}).get('time', 0),
        stats.get('extract', {}).get('time', 0),
        stats.get('index', {}).get('time', 0),
        stats.get('fill', {}).get('time', 0),
    ])
    
    report_lines.extend([
        f"## Performance",
        f"- **Total time:** {total_time:.2f}s ({total_time/60:.1f} minutes)",
        f"",
        f"---",
        f"*Generated by comune_extractor v2.0*"
    ])
    
    # Write report
    output_path.parent.mkdir(parents=True, exist_ok=True)
    with open(output_path, 'w', encoding='utf-8') as f:
        f.write('\n'.join(report_lines))
